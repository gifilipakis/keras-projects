{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Data in list format #####\n",
    "\n",
    "\n",
    "#Todas as sequências tem o mesmo comprimento\n",
    "#Vetores de tamanho fixo\n",
    "data_set = ['Lista', 'Pilha', 'Fila', 'Lista Simplesmente Encadeada', 'Lista Duplamente Encadeada', 'Árvore', '9',\n",
    "             'Pilha', 'Fila', 'Lista', 'Lista Simplesmente Encadeada', 'Lista Duplamente Encadeada', 'Árvore', '6',\n",
    "             'Árvore', 'Pilha', 'Fila', 'Lista', 'Lista Simplesmente Encadeada', 'Lista Duplamente Encadeada', '5',\n",
    "             'Pilha', 'Lista', 'Lista Simplesmente Encadeada', 'Lista Duplamente Encadeada', 'Fila', 'Árvore', '6']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['5', '6', '9', 'Fila', 'Lista', 'Lista Duplamente Encadeada', 'Lista Simplesmente Encadeada', 'Pilha', 'Árvore']\n",
      "9 itens distintos\n"
     ]
    }
   ],
   "source": [
    "##### Data in list format #####\n",
    "\n",
    "#itens distintos \n",
    "vocab_l = sorted(set(data_set))\n",
    "print(vocab_l)\n",
    "print ('{} itens distintos'.format(len(vocab_l)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  '5' :   0,\n",
      "  '6' :   1,\n",
      "  '9' :   2,\n",
      "  'Fila':   3,\n",
      "  'Lista':   4,\n",
      "  'Lista Duplamente Encadeada':   5,\n",
      "  'Lista Simplesmente Encadeada':   6,\n",
      "  'Pilha':   7,\n",
      "  'Árvore':   8,\n",
      "  ...\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Creating a mapping from unique characters to indices\n",
    "\n",
    "char2idx = {u:i for i, u in enumerate(vocab_l)}\n",
    "idx2char = np.array(vocab_l)\n",
    "\n",
    "text_as_int = np.array([char2idx[c] for c in data_set])\n",
    "\n",
    "print('{')\n",
    "for char,_ in zip(char2idx, range(20)):\n",
    "    print('  {:4s}: {:3d},'.format(repr(char), char2idx[char]))\n",
    "print('  ...\\n}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([4 7 3 6 5 8 2], shape=(7,), dtype=int32)\n",
      "tf.Tensor([7 3 4 6 5 8 1], shape=(7,), dtype=int32)\n",
      "tf.Tensor([8 7 3 4 6 5 0], shape=(7,), dtype=int32)\n",
      "tf.Tensor([7 4 6 5 3 8 1], shape=(7,), dtype=int32)\n",
      "'ListaPilhaFilaLista Simplesmente EncadeadaLista Duplamente EncadeadaÁrvore9'\n",
      "'PilhaFilaListaLista Simplesmente EncadeadaLista Duplamente EncadeadaÁrvore6'\n",
      "'ÁrvorePilhaFilaListaLista Simplesmente EncadeadaLista Duplamente Encadeada5'\n",
      "'PilhaListaLista Simplesmente EncadeadaLista Duplamente EncadeadaFilaÁrvore6'\n"
     ]
    }
   ],
   "source": [
    "##### Create training examples and targets #####\n",
    "\n",
    "# The maximum length sentence we want for a single input in characters\n",
    "seq_length = 6\n",
    "examples_per_epoch = len(data_set)#(seq_length+1)\n",
    "\n",
    "char_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)\n",
    "# for i in char_dataset:\n",
    "#     print(i)\n",
    "\n",
    "sequences = char_dataset.batch(seq_length+1, drop_remainder=True)\n",
    "\n",
    "#print batches encoded\n",
    "for i in sequences:\n",
    "    print(i)\n",
    "    \n",
    "#print batches as text\n",
    "for item in sequences.take(5):\n",
    "    print(repr(''.join(idx2char[item.numpy()])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input data:  'ListaPilhaFilaLista Simplesmente EncadeadaLista Duplamente EncadeadaÁrvore' \n",
      "\n",
      "Target data: 'PilhaFilaLista Simplesmente EncadeadaLista Duplamente EncadeadaÁrvore9' \n",
      "\n",
      "Input data:  'PilhaFilaListaLista Simplesmente EncadeadaLista Duplamente EncadeadaÁrvore' \n",
      "\n",
      "Target data: 'FilaListaLista Simplesmente EncadeadaLista Duplamente EncadeadaÁrvore6' \n",
      "\n",
      "Input data:  'ÁrvorePilhaFilaListaLista Simplesmente EncadeadaLista Duplamente Encadeada' \n",
      "\n",
      "Target data: 'PilhaFilaListaLista Simplesmente EncadeadaLista Duplamente Encadeada5' \n",
      "\n",
      "Input data:  'PilhaListaLista Simplesmente EncadeadaLista Duplamente EncadeadaFilaÁrvore' \n",
      "\n",
      "Target data: 'ListaLista Simplesmente EncadeadaLista Duplamente EncadeadaFilaÁrvore6' \n",
      "\n"
     ]
    }
   ],
   "source": [
    "##### Create training examples and targets #####\n",
    "\n",
    "def split_input_target(chunk):\n",
    "    input_text = chunk[:-1]\n",
    "    target_text = chunk[1:]\n",
    "    return input_text, target_text\n",
    "\n",
    "#foreach item in sequences apply split_input_target\n",
    "dataset = sequences.map(split_input_target)\n",
    "\n",
    "#print input_text and target_text as text\n",
    "#não necessário, para visualização\n",
    "for input_example, target_example in  dataset:\n",
    "    print ('Input data: ', repr(''.join(idx2char[input_example.numpy()])),'\\n')\n",
    "    print ('Target data:', repr(''.join(idx2char[target_example.numpy()])),'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step    0\n",
      "  input: 4 ('Lista')\n",
      "  expected output: 7 ('Pilha')\n",
      "Step    1\n",
      "  input: 7 ('Pilha')\n",
      "  expected output: 3 ('Fila')\n",
      "Step    2\n",
      "  input: 3 ('Fila')\n",
      "  expected output: 6 ('Lista Simplesmente Encadeada')\n",
      "Step    3\n",
      "  input: 6 ('Lista Simplesmente Encadeada')\n",
      "  expected output: 5 ('Lista Duplamente Encadeada')\n",
      "Step    4\n",
      "  input: 5 ('Lista Duplamente Encadeada')\n",
      "  expected output: 8 ('Árvore')\n",
      "Step    5\n",
      "  input: 8 ('Árvore')\n",
      "  expected output: 2 ('9')\n",
      "------------------------------------------------------------------\n",
      "Step    0\n",
      "  input: 7 ('Pilha')\n",
      "  expected output: 3 ('Fila')\n",
      "Step    1\n",
      "  input: 3 ('Fila')\n",
      "  expected output: 4 ('Lista')\n",
      "Step    2\n",
      "  input: 4 ('Lista')\n",
      "  expected output: 6 ('Lista Simplesmente Encadeada')\n",
      "Step    3\n",
      "  input: 6 ('Lista Simplesmente Encadeada')\n",
      "  expected output: 5 ('Lista Duplamente Encadeada')\n",
      "Step    4\n",
      "  input: 5 ('Lista Duplamente Encadeada')\n",
      "  expected output: 8 ('Árvore')\n",
      "Step    5\n",
      "  input: 8 ('Árvore')\n",
      "  expected output: 1 ('6')\n",
      "------------------------------------------------------------------\n",
      "Step    0\n",
      "  input: 8 ('Árvore')\n",
      "  expected output: 7 ('Pilha')\n",
      "Step    1\n",
      "  input: 7 ('Pilha')\n",
      "  expected output: 3 ('Fila')\n",
      "Step    2\n",
      "  input: 3 ('Fila')\n",
      "  expected output: 4 ('Lista')\n",
      "Step    3\n",
      "  input: 4 ('Lista')\n",
      "  expected output: 6 ('Lista Simplesmente Encadeada')\n",
      "Step    4\n",
      "  input: 6 ('Lista Simplesmente Encadeada')\n",
      "  expected output: 5 ('Lista Duplamente Encadeada')\n",
      "Step    5\n",
      "  input: 5 ('Lista Duplamente Encadeada')\n",
      "  expected output: 0 ('5')\n",
      "------------------------------------------------------------------\n",
      "Step    0\n",
      "  input: 7 ('Pilha')\n",
      "  expected output: 4 ('Lista')\n",
      "Step    1\n",
      "  input: 4 ('Lista')\n",
      "  expected output: 6 ('Lista Simplesmente Encadeada')\n",
      "Step    2\n",
      "  input: 6 ('Lista Simplesmente Encadeada')\n",
      "  expected output: 5 ('Lista Duplamente Encadeada')\n",
      "Step    3\n",
      "  input: 5 ('Lista Duplamente Encadeada')\n",
      "  expected output: 3 ('Fila')\n",
      "Step    4\n",
      "  input: 3 ('Fila')\n",
      "  expected output: 8 ('Árvore')\n",
      "Step    5\n",
      "  input: 8 ('Árvore')\n",
      "  expected output: 1 ('6')\n",
      "------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#não necessário, para visualização\n",
    "for input_example, target_example in  dataset:\n",
    "    for i, (input_idx, target_idx) in enumerate(zip(input_example, target_example)):\n",
    "        print(\"Step {:4d}\".format(i))\n",
    "        print(\"  input: {} ({:s})\".format(input_idx, repr(idx2char[input_idx])))\n",
    "        print(\"  expected output: {} ({:s})\".format(target_idx, repr(idx2char[target_idx])))\n",
    "    print('------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<BatchDataset shapes: ((1, 6), (1, 6)), types: (tf.int32, tf.int32)>\n",
      "(<tf.Tensor: shape=(1, 6), dtype=int32, numpy=array([[8, 7, 3, 4, 6, 5]])>, <tf.Tensor: shape=(1, 6), dtype=int32, numpy=array([[7, 3, 4, 6, 5, 0]])>)\n",
      "(<tf.Tensor: shape=(1, 6), dtype=int32, numpy=array([[7, 4, 6, 5, 3, 8]])>, <tf.Tensor: shape=(1, 6), dtype=int32, numpy=array([[4, 6, 5, 3, 8, 1]])>)\n",
      "(<tf.Tensor: shape=(1, 6), dtype=int32, numpy=array([[7, 3, 4, 6, 5, 8]])>, <tf.Tensor: shape=(1, 6), dtype=int32, numpy=array([[3, 4, 6, 5, 8, 1]])>)\n",
      "(<tf.Tensor: shape=(1, 6), dtype=int32, numpy=array([[4, 7, 3, 6, 5, 8]])>, <tf.Tensor: shape=(1, 6), dtype=int32, numpy=array([[7, 3, 6, 5, 8, 2]])>)\n"
     ]
    }
   ],
   "source": [
    "##### Create training batches #####\n",
    "\n",
    "# Batch size\n",
    "BATCH_SIZE = 1\n",
    "\n",
    "# Buffer size to shuffle the dataset\n",
    "# (TF data is designed to work with possibly infinite sequences,\n",
    "# so it doesn't attempt to shuffle the entire sequence in memory. Instead,\n",
    "# it maintains a buffer in which it shuffles elements).\n",
    "BUFFER_SIZE = 10\n",
    "\n",
    "# print(dataset)\n",
    "# for i in dataset:\n",
    "#     print(i)\n",
    "\n",
    "datasetBatch = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n",
    "# If your program depends on the batches having the same outer dimension,\n",
    "# you should set the drop_remainder argument to True to prevent the smaller\n",
    "# batch from being produced.\n",
    "\n",
    "print(datasetBatch)\n",
    "for i in datasetBatch:\n",
    "    print(i)\n",
    "\n",
    "\n",
    "#for i in datasetBatch.take(1):\n",
    "#    for j in i:\n",
    "#        for a in j:\n",
    "#            for e in a:\n",
    "#                print(''.join(label_encoder.inverse_transform([np.argmax(e)])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Building the model #####\n",
    "\n",
    "# Length of the vocabulary in chars\n",
    "vocab_size = len(vocab_l)\n",
    "\n",
    "# The embedding dimension\n",
    "embedding_dim = 256\n",
    "\n",
    "# Number of RNN units\n",
    "rnn_units = 1024\n",
    "\n",
    "def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Embedding(vocab_size, embedding_dim,\n",
    "                          batch_input_shape=[batch_size, None]),\n",
    "        tf.keras.layers.LSTM(rnn_units,\n",
    "                        return_sequences=True,\n",
    "                        stateful=True,\n",
    "                        recurrent_initializer='glorot_uniform'),\n",
    "        tf.keras.layers.Dense(vocab_size)\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "model = build_model(\n",
    "    vocab_size = len(vocab_l),\n",
    "    embedding_dim=embedding_dim,\n",
    "    rnn_units=rnn_units,\n",
    "    batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (1, None, 256)            2304      \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (1, None, 1024)           5246976   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (1, None, 9)              9225      \n",
      "=================================================================\n",
      "Total params: 5,258,505\n",
      "Trainable params: 5,258,505\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    " model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: tf.Tensor([[8 7 3 4 6 5]], shape=(1, 6), dtype=int32)\n",
      "\n",
      "Target: tf.Tensor([[7 3 4 6 5 0]], shape=(1, 6), dtype=int32)\n",
      "\n",
      "Batche Predictions: tf.Tensor(\n",
      "[[[-0.00162221 -0.00026628 -0.00346668 -0.00449064 -0.00406137\n",
      "    0.00018725 -0.00035133 -0.00317207  0.00271029]\n",
      "  [ 0.00336596 -0.00823973 -0.00210959  0.00280748 -0.00663296\n",
      "    0.00014146 -0.00516854 -0.00624472 -0.0050321 ]\n",
      "  [ 0.00165804 -0.00247024 -0.00479421  0.00583282 -0.00332201\n",
      "    0.0028725  -0.00632217 -0.00103183  0.00545756]\n",
      "  [ 0.00139558 -0.00020239 -0.00824285  0.00476362  0.00167502\n",
      "   -0.00103394 -0.00478953 -0.00083874  0.00717098]\n",
      "  [ 0.00136414  0.00578063  0.00127151  0.01175594  0.00074629\n",
      "   -0.00318136 -0.00796716 -0.00792722  0.00146125]\n",
      "  [ 0.00253247  0.00446041  0.00039789  0.01307701  0.00324432\n",
      "   -0.00328533 -0.00587091 -0.00195501  0.00698574]]], shape=(1, 6, 9), dtype=float32) # (batch_size, sequence_length, vocab_size)\n",
      "\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "logits should be a matrix, got shape [1,6,9] [Op:Multinomial]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-203821164d55>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m     \u001b[0msampled_indices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcategorical\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexample_batch_predictions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_samples\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m     \u001b[0msampled_indices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msampled_indices\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Sample Indices:'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msampled_indices\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\cristina filipakis\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\ops\\random_ops.py\u001b[0m in \u001b[0;36mcategorical\u001b[1;34m(logits, num_samples, dtype, seed, name)\u001b[0m\n\u001b[0;32m    451\u001b[0m   \"\"\"\n\u001b[0;32m    452\u001b[0m   \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"categorical\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mlogits\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 453\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mmultinomial_categorical_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_samples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    454\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    455\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\cristina filipakis\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\ops\\random_ops.py\u001b[0m in \u001b[0;36mmultinomial_categorical_impl\u001b[1;34m(logits, num_samples, dtype, seed)\u001b[0m\n\u001b[0;32m    459\u001b[0m   \u001b[0mseed1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseed2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrandom_seed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_seed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    460\u001b[0m   return gen_random_ops.multinomial(\n\u001b[1;32m--> 461\u001b[1;33m       logits, num_samples, seed=seed1, seed2=seed2, output_dtype=dtype)\n\u001b[0m\u001b[0;32m    462\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    463\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\cristina filipakis\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\ops\\gen_random_ops.py\u001b[0m in \u001b[0;36mmultinomial\u001b[1;34m(logits, num_samples, seed, seed2, output_dtype, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 53\u001b[1;33m       \u001b[0m_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     54\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m       \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\cristina filipakis\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[1;34m(e, name)\u001b[0m\n\u001b[0;32m   6841\u001b[0m   \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\" name: \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6842\u001b[0m   \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6843\u001b[1;33m   \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   6844\u001b[0m   \u001b[1;31m# pylint: enable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6845\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\cristina filipakis\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\six.py\u001b[0m in \u001b[0;36mraise_from\u001b[1;34m(value, from_value)\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: logits should be a matrix, got shape [1,6,9] [Op:Multinomial]"
     ]
    }
   ],
   "source": [
    "##### Testing the model #####\n",
    "\n",
    "for input_example_batch, target_example_batch in datasetBatch:\n",
    "    print('Input:',input_example_batch)\n",
    "    print()\n",
    "    \n",
    "    print('Target:',target_example_batch)\n",
    "    print()\n",
    "    \n",
    "    example_batch_predictions = model(input_example_batch)\n",
    "    print('Batche Predictions:',example_batch_predictions, \"# (batch_size, sequence_length, vocab_size)\")\n",
    "    print()\n",
    "    \n",
    "    sampled_indices = tf.random.categorical(example_batch_predictions, num_samples=1)\n",
    "    sampled_indices = tf.squeeze(sampled_indices,axis=-1).numpy()\n",
    "    print('Sample Indices:',sampled_indices)\n",
    "    print('--------------------------------------------------------')\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[ 0.01447803 -0.00242894 -0.01396178  0.02150395  0.01190736 -0.00065227\n",
      "   0.01840041 -0.00205957  0.00655539]], shape=(1, 9), dtype=float32)\n",
      "[8]\n"
     ]
    }
   ],
   "source": [
    "##### Try prediction for the first example in the batch #####\n",
    "\n",
    "#print(example_batch_predictions)\n",
    "#sampled_indices = tf.random.categorical(example_batch_predictions, num_samples=1)\n",
    "#sampled_indices = tf.squeeze(sampled_indices,axis=-1).numpy()\n",
    "#print(sampled_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
